

## 实习周记





第二个工作周

2019.11.17

今日完成：

1) 学习golang包引用、嵌套、作用域

2) Mac与Linux系统pip安装

3) 运行并分析Piotr的python脚本

4) 阅读Piotr项目的文档

明日计划：

1) 与Piotr交流脚本中关于GPU和部署信息的获取

2) 学习代码中关于接口的调用

2019.11.18

今日完成:

1) 和Piotr针对数据需求的沟通

2) 使用Piotr的接口导出excel

3) python正则表达式学习

明日计划:

1) 跟进服务管理的需求

2) python多线程学习(if available)

2019.11.19

今日完成：

1) python基础复习

2) python多线程&IO学习

明日计划：

1) 跟进服务治理项目

2019.11.20

今日完成：

1) 测试内部推送字段

2) redis环境安装（Linux & Mac ）以及python-redis学习

3) 阅读metrics接口文档

遇到问题：

1) metrics接口文档阅读难度过大

明日计划：

1) 通过联系设计人弄懂api的使用方法

2) 跟进服务治理项目

2019.11.21

今日完成：

1) 完成metrics文档的阅读

2) 阅读文档提供的python api脚本并调通metrics api

3) 部分Linux指令的学习

明日计划：

1) 跟进服务治理项目

2) 学习request, time, datetime等相关python包

3) vim-python环境搭建(if available) 

2019.11.22

今日完成：

1) 完善对metrics api 和 service tree api的封装，并对其中的一些字段进一步了解

2) 推送接口和上述两接口的初步组装 

3) 项目中所需python包的学习

未完成：

1) vim-python环境搭建

周末计划：

1) 复习git 分支管理

2) 由于项目中使用Linux较多，针对性学习一些指令（python, vim等）

3) 搭建vim环境(if available)

第三个工作周

2019.11.25

今日完成：

1）初步实现计量计费推送脚本的主体结构。发现coutner值与qps值对应，因此可以通过counter值对访=问总数的统计。针对每个metrics_name，根据tagkv中对user字段的分组，获取每个psm的所有metics_name的所有资源使用者及其访问数。

2）凌晨前上线测试版，以便次日查看推送效果。

明日计划：

1）跟进服务治理项目需求

2019.11.26

今日完成：

1）维护计量计费推送的文档；

2）代码调整优化。

3）加入tos模块，但在晚上时上传数据遇到bug，改为devbox开发环境后依然错误类型改变，但是依旧返回404错误。问题于当日下班前没有解决。

明日计划：

1）解决tos模块的错误

2019.11.27

今日完成：

1）通过on call查询得知由于dev box线上环境是boe，因此上传失败。切换至lf数据源后可正常推送。

与mentor review脚本代码，同步到git。

2）处理简单文本分析，得到不重复的id list。

明日计划：

1）跟进项目

2019.11.28

1）走了一遍上线定时任务的流程：devbox上测试无误后，将代码从gitlab发布至scm；在定时任务平台为该脚本创建一个集群。因为需要使用pytos，因此需要在任务设中从scm拉取pytos项目并放在环境变量的目录下或为其添加环境变量。尝试几次crontab后成功跑通服务。

2）维护该项目文档，调整大纲级别，增加功能描述，删除不必要的内容。

明日计划：

1）跟进项目

2019.11.29 

今日完成：

1）发现昨天使用线上环境的推送部分失败，原因是有些user psm不能找到其对应的服务树路径。之后询问metrics api的oncall，了解到user psm等所有数据是由打点方传上来的。观察发现有些服务是在正确的psm上加了用下划线连接的后缀。因此，尝试将这类user psm处理之后得到路径。但是仍然有一些user psm不能得到其路径。

2）学习了一下操作redis五种数据结构的相关指令。

2019.12.1

今日完成：

1）整理出价格高的不合法user psm和其对应metric name。

2）安装image_enhance项目环境，跑通了一次原始项目的流程，观察到图像处理的结果。在迁移代码的过程中遇到了导包失败的问题，于下班前未能解决。

明日计划：

1）解决迁移后项目中的导包问题

第四个工作周

2019.12.2

今日完成：

1）解决了导包问题并整理image_enhance的代码，跑通一次图片处理的流程。

2）在cv_measure_service中使用piotr之前写的service_tree_stats项目获取cpu，gpu, mem等数据。

3）学习shell语言基础

明日计划：

1）实现获取并存储cpu, gpu等数据，并将其和前一天的数据进行比较，筛出新增、减少、使用量过低的服务。

2019.12.3

今日完成：

1）上午完成了获取、存储、比较的代码，还剩发送lark群提示消息的功能未实现。

2）下午将image_enhance_service项目中rpc的部分从使用自己编译生成的py文件转换为使用euler框架，并跑通流程。

3）调通了一次client远程调用image_enhance_service并获取结果的流程。

明日计划：

1）完成cv_measure_service中lark群消息提示的功能。

2019.12.4

今日完成：

1）cv_service_measure加入lark群内发消息的功能，推送每日新增、删除、资源使用量过低的服务

2）整理image_enhance_serivice里项目启动的代码，并在下班前上线测试版服务，跑通几组测试图片

明日计划：

1）跟进上述两个项目

2）继续学习shell编程

2019.12.5

今日完成：

1）整理image_enhance_service中的logger，使用公司的流逝日志框架输出耗时等信息

2）继续学习shell编程，整理笔记

3）给榕鑫写文本提取的脚本

明日计划：

1）跟进上述两个项目

2019.12.6

今日完成：

1）将项目中的两个uslab rpc切换至16位浮点数的服务，原本需要花费数十秒的f.jpg现在降到若干秒。但是将增强结果与分割结果合并的过程耗时超过1秒。

2）学习shell编程，整理笔记

第五个工作周

2019.12.9

今日完成：

1）修复计费服务在网路请求发生异常时不能获取数据的bug，当日重新上线。

2）将切换至float16的图像增强服务上线，编写其api文档。

明日计划：

1）跟进图像增强和计量计费项目需求

2019.12.10

今日完成：

1）计量计费项目中加入at项目负责人的功能，通过piotr的脚本可获得服务的psm和其负责人的邮箱前缀，通过该前缀可以获得user id；在lark api中加入这个user id list就可以at到响应的用户

2）在项目中总结vim、git的使用问题，继续学习欠缺使用方法

明日计划：

1）跟进图像增强和计量计费项目需求

2）学习Linux系统管理相关的指令

2019.12.11

今日完成：

1）Linux系统管理和文本操作指令学习

2）server_sample服务端模版学习

明日计划：

1）跟进项目需求

2）学习项目中使用到的python包

2019.12.12

今日完成：

1）复习&学习python numpy包

2）修补计量计费脚本中获取资源使用方path的问题，重新上线

明日计划：

1）跟进两个项目的需求

2）学习python opencv包

2019.12.13

今日完成：

1）测试image_enhance_service项目，控制变量地改变服务端进程数和访问并发数，并统计出相应的耗时

2）在quota_service中加入获取并推送AI-Lab CV节点的quota详细信息

明日计划：

1）完善quota_service，加入服务的资源变化量提醒和资源使用量过低的服务报警功能

2019.12.15

今日完成：

1）补充quota_service的功能，加入了服务站用的资源变化量提醒和资源使用量过低服务报警。

2）协助客户端RD同学寻找image_enhance项目中的问题所在；将base64码转换成image核对信息。

遇到问题：

1）原以为已经将image_enhance_service接入了流式日志，但上线以后发现没有

明日计划：

1）将项目接入流式日志

第六个工作周

2019.12.16

今日完成：

1）和客户端的同学联调，发现问题在于对方没有调用image_enhance_service，在对方切换至本服务后，又遇到了问题。当时误认为是因为服务在更新所导致的错误。当时更新完之后对方没有继续调用。

2）在查阅文档后得知未接入监控和日志的原因是没有配置框架、类型等服务信息；配置成功后可以接入

明日计划：

1）继续联调

2019.12.17

今日完成：

1）和VE侧同学联调后发现是对方thrift的transport与我们的不同，应该是framed，将其纠正。之后和mentor review了当前代码。将两个模型打包放到tos上，并加上了调用uslab的超时。

2）修复图片效果为蓝的bug，在下班前上线；上线版本采取jpg格式存图，quality设为100。

明日计划：

1）继续联调

2019.12.18

今日完成：

1）将线上项目的压缩方式改变为png无损压缩，并且测了多组图片得到的耗时；目前的耗时还不符合预期，主要的延时在北美lab的算法。

2）修复image_enhance服务中metrics打点异常的问题（之前由于代码中写的变量不对）

3）复习golang基础

明日计划：

1）配合超清人像项目的联调

2）继续复习golang基础

2019.12.19

今日完成：

1）在联调超清人像项目的过程中发现了效果不对齐的原因在于合并的代码有误，在修正后重新上线。

2）优化了第一次调接口才会加载模型的问题，让服务启动时自动加载模型。

3）复习golang基础

明日计划：

1）测试项目的延时和qps等数据

2）配合排查联调中可能存在的问题

2019.12.20

今日完成：

1）测试线上服务的延时和qps，得到的结果是当所跑图片都是在1MB以下的jpg时，可以达到3.5qps，延时为540ms。但是如果跑的图片都是联调群里的测试图的话，则延时很大，大概在5-6s，qps只有0.5-0.6。

2）给彭威跑图的时候发现跑heic格式的图片，服务端读入不支持，后来确认了客户端只会上传jpg格式的图片，因而排除问题。

第七个工作周

2019.12.23

今日完成：

1）完善图像增强中对uslab调用可能发生的错误的处理，增加错误代码文件管理error code常量

2）测试联调群中发的两组测试图，跑10次统计平均值；发现有两张图的尺寸不符合uslab的要求，已向刘鼎反应

明日计划：

1）继续学习&复习go

2019.12.24

今日完成：

1）与东伟和彭威等进行会议，得到了将labcv上游服务的超时设置为10s；维护项目文档，补充图片尺寸和格式限制等。晚上更新上线了只包含前景模型的服务。

2）测试调用uslab服务的网络通信时间和算法时间占比。发现lq机房的服务调用uslab反而会在大图情况下变得很慢(10s+)。

明日计划：

1）继续学习&复习go，尝试用go语言搭建thrift服务

2019.12.25

今日完成：

1）测试只使用前景模型的image_enhance服务的qps，测得结果为0.9左右。

2）下午尝试搭建go thrift服务端，遇到thrfit版本与go语言版本不兼容的问题。

3）初步阅读arscan_server代码，在本地起项目的过程中遇到了权限不足的问题。

明日计划：

1）获取权限并在本地跑起arscan_server

2）解决go与thrift版本问题

2019.12.26

今日未完成：

1）在获得项目后，第一时间思考的是如何在本地配置环境，忽视了cmake文件里的include目标，因此在环境问题上浪费了很多时间。先后在本机上编译安装了boost和opencv，但最后仍然缺失了一些库文件的依赖，于下班前未成功运行项目。

2019.12.27

今日未完成：

1）在阅读了CMakeList里的编译链接过程之后，意识到依赖的头文件、库文件应来自一个第三方资源目录下。从算法同学处得到该目录下的文件后，其中包括thrift、boost、opencv等源文件和动态库文件。但是发现在链接过程中thrift依赖中会产生错误，尝试在不同开发机、不同gcc版本的情况下都无法通过编译。

*下班前mentor采用blade构建依赖并成功编译

2019.12.29

今日完成：

1）将使用blade构建到本地后，发现还是会出现libssl文件中的一系列变量reference undefined的问题，而且无论thrift.so文件是否链接到/usr/local/lib/下的libssl文件，其下的变量都无法被引用。在重新安装openssl_1.0.0后错误还是存在，排除了libssl文件本身损坏，尝试改变依赖的thrift版本。由0.9.1.2切换至0.9.1后解决成功编译。修改启动脚本并上线。

今日未完成：

1）构建客户端时发现有thrift库中的TSocket reference undefined问题，多次尝试修改BUILD后仍未查明原因。

第八个工作周

2019.12.30

今日完成：

1）复用之前项目(image enhance)中的python客户端代码，编写出现在的python客户端，测试本地和线上服务，目前服务能成功返回结果。*但由于正确性需要在移动端验证，目前无法在开发机上对客户端返回的结果进行正确性验证。

2）更新超清人像线上服务，并配置其报警监控。

3）c++、linux杂项学习。

明日计划：

1）完善资源信息推送的项目

2019.12.31

今日完成：

1）依赖于arscan的python客户端，开发基于flask的http服务。暴露restful api，使用base64编码传输图片和模型。相当于在rpc接口外包装了一层http接口。编写相应的python客户端进行接口测试。

2）由于image_enhance项目中需要在服务端完成匀肤功能，因此向算法RD提供调用106关键点的客户端demo。

2020.1.2

今日完成：

1）将arscan http server整合到creat tob项目中。今日在处理代码的时候发生了切换版本导致的冲突问题，之后使用了git reset --hard命令导致失去一部分工作区代码；之后了解了git reset 选项(hard mixed soft)的区别，以提升开发效率。

2）复习golang基础，包括结构体与接口相关

明日计划：

1）arscan api联调

2）熟悉swagger的使用

2020.1.3

今日完成：

1）将人脸关键点功能整合到项目中，更新build脚本。但之后遇到了本地服务会在某处语句crash的情况，但在他人环境中都能正常运行，上线之后也能正常运行，暂时没有发现原因。现已更新至线上。

2）学习open api的规范和swagger接口文档编写。

明日计划：

1）学习go并发相关基础、库使用

2）继续学习使用swagger工具

2020.1.5

今日完成：

1）arscan http server代码review并规范化：修改易造成混淆的函数命名、rpc部分代码化简、rpc超时设置

2）swagger OAS 3学习，golang并发、单向通道初步学习

3）阅读限流相关文档，了解大致配置流程和注意事项（如框架版本要求等）

4）完善tce资源监控服务的细节（补充推送字段等）

明日计划：

1）解决日志无法纳入调用链构建的问题

2）继续学习golang编程并发相关

第九个工作周

2020.1.6

今日完成：

1）tce资源监控项目开发，加入每个服务的各个集群资源量信息；由于获得的数据结构较为复杂，导致代码可读性较差，因此在某些步骤代码复用以减少后续维护的困难；资源使用量前后对比的时间差值改变为12小时。

问题：

1）服务的日志调用链构建依然存在问题，尝试更新rpc框架版本(euler)至次新版(0.17.0)，以及更新logsdk(bytedlogger)至最新版(0.4.0)，结果无变化。考虑是否是上游rpc框架的版本问题.

2020.1.7

今日完成：

1）将推送的tce资源信息细化到机房；之前从tos获取的数据还存在反序列化问题，目前已解决；文档中添加项目各模块的说明

2）整合超清人像中算法RD添加的功能，调整代码版本，重新上线；日志功能问题得到部分解决，目前能看到调用的链路，但人像服务中log为空，显然还存在问题。

明日计划：

1）跟进tce quota项目需求。

2020.1.8

今日完成：

1）tce quota脚本中的service-tree-stats sdk的调用开始出现失败的情况，加入对应的出错处理。若最终无法获得服务资源信息则任务失败。

2）go并发、管道相关学习

明日计划：

1）上手go http框架

2020.1.9

今日完成：

1）超清人像lq机房的服务会在某些case中耗时夸张，排查后定位到是在uslab返回响应的部分会有超长的耗时，目前原因未知，并且之后在lq机房的服务会遇到该问题，alinc2和hl则不存在。

2）超轻人像的rpc base字段带上logid和caller，尝试解决构造链失败的问题。

明日计划：

1）利用之前的arscan http server搭目标arscan demo server

2）解决超清人像日志问题

 

2020.1.10

今日完成：

1）模型生成服务demo中，将调用逻辑转到自己写的http server。

2）creat_tob项目，业务方出现了模型不符合预期的问题。但我方直接rpc得到的结果和客户端自测得到的模型是正确的。目前暂时提供一个供测试的不经过转码的接口；同时老接口记录中间过程（图片，图片的base64编码以及编码前的文件），以排查问题。

第十周

2020.1.13

今日完成：

1）修改creat_TOB接口，传入图片压缩包，返回模型压缩包。和业务方沟通后确定了使用http的状态码区分成功与否，若status==200则视作成功，直接读取响应体的二进制文件；否则失败，解析响应体的json数据。

明日计划：

1）已上线服务的测试、配置等工作。

2020.1.14

今日完成：

1）阅读压测平台的相关文档，使用该平台测试超清人像服务；对binary字段的变量，要注意引用base64码变量需要对"号转码。 

2）学习net/http源码，请求处理过程，理解gin框架和http库的边界。

明日计划：

1）学习gin框架[Golang net/http和gin框架源码解读](https://bytedance.feishu.cn/docs/doccn9e8asc0rCiSP2U1bl#S5EK52) 

2020.1.15

今日完成：

1）对超清人像和老照片服务进行压测。压测超清人像的alinc2机房时发现发压网络时延过大，失败率高导致不能稳定在目标qps；老照片的压测正常。

2020.1.16

1）今日工作量不大，主要学习了一些常见的go和http知识。

2020.1.17

今日完成：

1）对调用链构造的问题，和oncall确认了rpc框架和logsdk版本无误后，找到问题可能是没有手动在代码中调用base_compat_middleware中间件。

明日（周日）计划：

1）和PM确认其http请求503的问题。

2020.1.19

今日完成：

1）和PM对接后发现503 error是由于序列不同导致的网络问题。因此上线creator_tob服务。中间遇到了安装依赖报错的情况，通过apt install build-essential python-dev解决问题。

2）超清人像服务中，手动添加log中间件，经过线上测试后认为能够解决调用链中lab cv的服务没有日志信息的问题。

第十一周

2020.1.20

今日完成：

1）按地区和物理集群筛出tce资源分配所需的信息。

2）完善tce监控脚本，增加AI-Lab CV资源总配额按机房分类。

明日计划：

1）跟进项目需求&自行学习

2020.1.21

今日完成：

1）数据平台代码preview（mvc部分）

2）复习http常用登陆、身份验证方式

明日计划：

1）数据平台代码preview（orm部分）

2）gorm学习

第十二周

2020.2.3

进度：

1）本地构建qs服务失败，查询后发现可能是系统和gcc版本差异的问题。但是不便更改gpu机器上的gcc版本，因此在docker容器中进行构建、运行。

明日计划：

1）

2020.2.4

进度：

1）通过debian8的容器构建qs服务，并在gpu资源的机器上起服务

2020.2.5

进度：

1）根据实际需求适当修改资源监控提示信息。

2020.2.6

进度：

1）

2020.3.23 - 2020.3.27

2020.3.25

1. 图像转3d，切换视频速率

1. 提供图像修复测试样例

2020.3.26

1. 全景图像参数调整，测试集回归并到线上联调

1. 图像转3d，增加5个rpc调用打点；增加合成视频的倍速参数。

2020.3.27

1. 图像转3d: 本地编译运行加入render逻辑后的服务；根据新的idl调整服务接口并上线。

2020.30 - 2020.4.1

2020.3.30

1. 图像转3d：添加更多部分的耗时打点并压测分析瓶颈，发现render部分延时随QPS上涨明显。

2020.3.31

2020.4.1